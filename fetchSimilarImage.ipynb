{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Necessary Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nfrom keras.preprocessing.image import load_img,img_to_array\nfrom keras import models, Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.xception import Xception\nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\nimport matplotlib.pyplot as plt\nimport PIL.Image as Image\nfrom scipy import spatial\nfrom sklearn.cluster import KMeans","execution_count":101,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_path = \"/kaggle/input/avantari-technologies-task/dataset/train/\"","execution_count":102,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def load_images_from_folder(folder):\n    images = []\n    for filename in os.listdir(folder):\n        img = load_img(os.path.join(folder,filename),  target_size =(224, 224)) \n        img = img_to_array(img)\n        img = img.reshape((1,) + img.shape)\n        if img is not None:\n            images.append(img)\n    return images","execution_count":103,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_names = os.listdir(\"/kaggle/input/avantari-technologies-task/dataset/train/\")\nfile_names.sort()\nprint('The number of  images: ', len(file_names))","execution_count":104,"outputs":[{"output_type":"stream","text":"The number of  images:  4738\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"function to load image from a folder"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_all_images():\n    images1 = load_images_from_folder(base_path)\n    all_imgs_arr = np.array(images1)\n    return all_imgs_arr","execution_count":105,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_imgs_arr = get_all_images()\npreds_all = np.zeros((len(all_imgs_arr),4096))","execution_count":106,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model to extract features using Xception Net form all images "},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg = VGG16(include_top=True)\nmodel2 = Model(vgg.input, vgg.layers[-2].output)\n# model2.save('vgg_4096.h5') # saving the model just in case","execution_count":107,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_imgs_arr.shape","execution_count":108,"outputs":[{"output_type":"execute_result","execution_count":108,"data":{"text/plain":"(4738, 1, 224, 224, 3)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Method to store all the extracted features and saved it as a dataframe\n* with file name as index and features a columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"file = \"op.csv\"\noutput = open(file, \"w\")\nfor j in range(all_imgs_arr.shape[0]):\n    featues = model2.predict(all_imgs_arr[j])\n    features = [str(f) for f in featues[0]]\n    output.write(\"%s,%s\\n\" % (file_names[j], \",\".join(features)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Viewing the Stored Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"op = pd.read_csv(\"op.csv\")\nop.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def img2array(im):\n    if im.mode != 'RGB':\n        im = im.convert(mode='RGB')\n    return np.fromstring(im.tobytes(), dtype='uint8').reshape((im.size[1], im.size[0], 3))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Query Image"},{"metadata":{"trusted":true},"cell_type":"code","source":"query_image = \"/kaggle/input/avantari-technologies-task/dataset/train/795.jpg\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qu_image = Image.open(query_image)\nquery_img_arr = img2array(qu_image)\nplt.figure()\nplt.imshow(query_img_arr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_names = query_image.split(\"/\")\nimg_name = img_names[-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_images_from_file(file_path):\n    images = []\n    img = image.load_img(file_path,  target_size=(224, 224))\n    img = image.img_to_array(img)\n    img = img.reshape((1,) + img.shape)\n    if img is not None:\n            images.append(img)\n    return images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_img_features = load_images_from_file(query_image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Extracting the features from the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_img_pred = model2.predict(new_img_features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Similarity function between two features "},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_similarity(vector1, vector2):\n return (1 - spatial.distance.cosine(vector1, vector2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"op.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"values = op[\"0.jpg\"]\nop = op.drop([\"0.jpg\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"similar_index = {}\nfor fea in range(0,len(op)):\n   sim_val = calculate_similarity(op.iloc[fea],new_img_pred)\n   similar_index.update({values[fea]:sim_val})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_similarity = {}\nfor key, value in sorted(similar_index.items(), key=lambda kv: kv[1], reverse=True):\n    sorted_similarity.update({key:value})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out = dict(list(sorted_similarity.items())[0: 10])\nsimilar_images = list(out.keys())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Construct Path for the images to load "},{"metadata":{"trusted":true},"cell_type":"code","source":"all_img_path = []\nfor img in similar_images:\n    new_path = base_path+img\n    all_img_path.append(new_path)\nprint(all_img_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images = [Image.open(f) for f in all_img_path ]\nnp_images = [ img2array(im) for im in images ]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Displaying the 10 similar images"},{"metadata":{"trusted":true},"cell_type":"code","source":"for img in np_images:\n    plt.figure()\n    plt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}